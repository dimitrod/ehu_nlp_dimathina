{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM/tDWIJGziUfznfBtxTmFH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitrod/ehu_nlp_dimathina/blob/chat_gpt/Guides/chat_gpt_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Test Environment\n",
        "Use this notebook to conduct single tests on the model of your choice"
      ],
      "metadata": {
        "id": "N6R7R18RhL1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import importlib"
      ],
      "metadata": {
        "id": "ZtAb_F5JHumN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"BRANCH\"] = \"chat_gpt\"\n",
        "os.environ[\"DIRECTORY\"] = \"ChatGPT\"\n",
        "os.environ[\"MODULE\"] = \"chat_gpt\"\n",
        "os.environ[\"CLASS\"] = \"chat_gpt\""
      ],
      "metadata": {
        "id": "GFVVjMQZEgao"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xFRvUd8FjTnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Execute the following script to import the model and install the requirements"
      ],
      "metadata": {
        "id": "iO2nNW6kjU1m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH1mqdP9XZBY",
        "outputId": "0ac55c17-c3d8-469b-bc75-0a12c9e08f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ehu_nlp_dimathina'...\n",
            "remote: Enumerating objects: 712, done.\u001b[K\n",
            "remote: Counting objects: 100% (247/247), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 712 (delta 139), reused 142 (delta 80), pack-reused 465 (from 1)\u001b[K\n",
            "Receiving objects: 100% (712/712), 28.01 MiB | 41.26 MiB/s, done.\n",
            "Resolving deltas: 100% (374/374), done.\n",
            "/content/ehu_nlp_dimathina\n",
            "Branch 'chat_gpt' set up to track remote branch 'chat_gpt' from 'origin'.\n",
            "Switched to a new branch 'chat_gpt'\n",
            "/content\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r ChatGPT/requirements.txt (line 1)) (1.57.4)\n",
            "Collecting httpx==0.23.0 (from -r ChatGPT/requirements.txt (line 2))\n",
            "  Downloading httpx-0.23.0-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m55.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.23.0->-r ChatGPT/requirements.txt (line 2)) (2024.12.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.23.0->-r ChatGPT/requirements.txt (line 2)) (1.3.1)\n",
            "Collecting rfc3986<2,>=1.3 (from rfc3986[idna2008]<2,>=1.3->httpx==0.23.0->-r ChatGPT/requirements.txt (line 2))\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore<0.16.0,>=0.15.0 (from httpx==0.23.0->-r ChatGPT/requirements.txt (line 2))\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (2.10.3)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r ChatGPT/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r ChatGPT/requirements.txt (line 1)) (1.2.2)\n",
            "Collecting h11<0.13,>=0.11 (from httpcore<0.16.0,>=0.15.0->httpx==0.23.0->-r ChatGPT/requirements.txt (line 2))\n",
            "  Downloading h11-0.12.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r ChatGPT/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r ChatGPT/requirements.txt (line 1)) (2.27.1)\n",
            "Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rfc3986, h11, httpcore, httpx\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "Successfully installed h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 rfc3986-1.5.0\n"
          ]
        }
      ],
      "source": [
        "directory = os.environ[\"DIRECTORY\"]\n",
        "\n",
        "!git clone --no-checkout https://github.com/dimitrod/ehu_nlp_dimathina.git\n",
        "%cd ehu_nlp_dimathina/\n",
        "!git sparse-checkout init --cone\n",
        "!git sparse-checkout set $DIRECTORY\n",
        "!git checkout $BRANCH\n",
        "%mv $DIRECTORY ..\n",
        "%cd ..\n",
        "%rm -r ehu_nlp_dimathina\n",
        "%rm -r sample_data\n",
        "!pip install -r {directory}/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an instance of the model"
      ],
      "metadata": {
        "id": "FAXrOR32ghSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "module = os.environ[\"MODULE\"]\n",
        "cls = os.environ[\"CLASS\"]\n",
        "\n",
        "module_path = f\"{directory}.{module}\"  # Combine directory and module\n",
        "module_obj = importlib.import_module(module_path)  # Import the module dynamically\n",
        "cls_obj = getattr(module_obj, cls)"
      ],
      "metadata": {
        "id": "_9BLKq_PgU9g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = [0.5]\n",
        "\n",
        "model = cls_obj(params)"
      ],
      "metadata": {
        "id": "EciLLl7vIGF9",
        "outputId": "85ad0d4c-215b-49d4-fd8a-918363e6a142",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Token: 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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "P_cg7cVsglsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests\n",
        "Start the tests that you want to conduct"
      ],
      "metadata": {
        "id": "zsoHYs5Fgnyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the capital of france?\"\n",
        "\n",
        "answer = model.invoke(question)\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "V_xw5na6gujx",
        "outputId": "ac2ee648-d5e7-4012-d3c1-37556598db82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris.\n"
          ]
        }
      ]
    }
  ]
}