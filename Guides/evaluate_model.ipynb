{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNE0NlWWLUcuUAs6Fp482bR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitrod/ehu_nlp_dimathina/blob/main/Guides/evaluate_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "In this script you can evaluate any model that has been developed during the project using the evaluation data.\n",
        "\n",
        "By default the evaluation data has been set to be the first 7900 questions from the train split of the triviaqa dataset.\n",
        "If you want to change the evaluation data to be a different split you can do that using the *load_evaluation_data.py* script in the utils package. A guide for this is in the section [Changing the Evaluation Data](#scrollTo=H294GP72zhM9).\n",
        "\n",
        "The following models are available\n",
        "\n",
        "*   (Dummy Model: Always gives the correct answer to the first 7900 questions)\n",
        "*   Tiny Llama\n",
        "*   Mistral (without RAG)\n",
        "*   rag with qa embeddings\n",
        "*   Listeneintrag\n",
        "*   Listeneintrag\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N6R7R18RhL1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xFRvUd8FjTnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Enter\n",
        "\n",
        "| Model | BRANCH | DIRECTORY | MODULE | CLASS | PARAMS | Note |\n",
        "|----------|----------|----------|----------|----------|----------|----------|\n",
        "|Dummy Model|main|Dummy_Model|dummy_model|dummy_model|2 test params|-|\n",
        "|Tiny Llama|tiny_llama|TinyLlama|tiny_llama|tinyllama|-|**very slow**|\n",
        "|Mistral without RAG|mistral-instruct-no-rag|MistralInstruct|mistral_instruct|mistral_instruct|-|**Huggingface Token and GPU required**|\n",
        "|RAG with QA Embeddings|rag_qa_embeddings|RAG_QA_Embeddings|rag_qa_embeddings|rag_qa_embeddings|k=contexts|-|"
      ],
      "metadata": {
        "id": "iO2nNW6kjU1m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qH1mqdP9XZBY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"BRANCH\"] = \"main\"\n",
        "os.environ[\"DIRECTORY\"] = \"Dummy_Model\"\n",
        "os.environ[\"MODULE\"] = \"dummy_model\"\n",
        "os.environ[\"CLASS\"] = \"\tdummy_model\"\n",
        "os.environ[\"PARAMS\"] = \"hello world\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following script to setup the evaluation environment"
      ],
      "metadata": {
        "id": "LFeS1s_SYl3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = os.environ[\"DIRECTORY\"]\n",
        "\n",
        "!git clone --no-checkout https://github.com/dimitrod/ehu_nlp_dimathina.git\n",
        "%cd ehu_nlp_dimathina/\n",
        "!git sparse-checkout init --cone\n",
        "!git sparse-checkout set Evaluation/\n",
        "!git checkout main\n",
        "%mv Evaluation/ ..\n",
        "!git sparse-checkout set $DIRECTORY\n",
        "!git checkout $BRANCH\n",
        "%mv $DIRECTORY ..\n",
        "%cd ..\n",
        "!git clone https://github.com/mandarjoshi90/triviaqa.git\n",
        "%rm -r ehu_nlp_dimathina\n",
        "%rm -r sample_data\n",
        "%cd triviaqa/\n",
        "!pip install -r requirements.txt\n",
        "%cd ../Evaluation\n",
        "!pip install -r requirements.txt\n",
        "%cd ../{directory}\n",
        "!pip install -r requirements.txt\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBLrZP5RYNg4",
        "outputId": "c8a4aa6e-50d1-4746-97bc-871333cf00d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ehu_nlp_dimathina'...\n",
            "remote: Enumerating objects: 351, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/203)\u001b[K\rremote: Counting objects:   1% (3/203)\u001b[K\rremote: Counting objects:   2% (5/203)\u001b[K\rremote: Counting objects:   3% (7/203)\u001b[K\rremote: Counting objects:   4% (9/203)\u001b[K\rremote: Counting objects:   5% (11/203)\u001b[K\rremote: Counting objects:   6% (13/203)\u001b[K\rremote: Counting objects:   7% (15/203)\u001b[K\rremote: Counting objects:   8% (17/203)\u001b[K\rremote: Counting objects:   9% (19/203)\u001b[K\rremote: Counting objects:  10% (21/203)\u001b[K\rremote: Counting objects:  11% (23/203)\u001b[K\rremote: Counting objects:  12% (25/203)\u001b[K\rremote: Counting objects:  13% (27/203)\u001b[K\rremote: Counting objects:  14% (29/203)\u001b[K\rremote: Counting objects:  15% (31/203)\u001b[K\rremote: Counting objects:  16% (33/203)\u001b[K\rremote: Counting objects:  17% (35/203)\u001b[K\rremote: Counting objects:  18% (37/203)\u001b[K\rremote: Counting objects:  19% (39/203)\u001b[K\rremote: Counting objects:  20% (41/203)\u001b[K\rremote: Counting objects:  21% (43/203)\u001b[K\rremote: Counting objects:  22% (45/203)\u001b[K\rremote: Counting objects:  23% (47/203)\u001b[K\rremote: Counting objects:  24% (49/203)\u001b[K\rremote: Counting objects:  25% (51/203)\u001b[K\rremote: Counting objects:  26% (53/203)\u001b[K\rremote: Counting objects:  27% (55/203)\u001b[K\rremote: Counting objects:  28% (57/203)\u001b[K\rremote: Counting objects:  29% (59/203)\u001b[K\rremote: Counting objects:  30% (61/203)\u001b[K\rremote: Counting objects:  31% (63/203)\u001b[K\rremote: Counting objects:  32% (65/203)\u001b[K\rremote: Counting objects:  33% (67/203)\u001b[K\rremote: Counting objects:  34% (70/203)\u001b[K\rremote: Counting objects:  35% (72/203)\u001b[K\rremote: Counting objects:  36% (74/203)\u001b[K\rremote: Counting objects:  37% (76/203)\u001b[K\rremote: Counting objects:  38% (78/203)\u001b[K\rremote: Counting objects:  39% (80/203)\u001b[K\rremote: Counting objects:  40% (82/203)\u001b[K\rremote: Counting objects:  41% (84/203)\u001b[K\rremote: Counting objects:  42% (86/203)\u001b[K\rremote: Counting objects:  43% (88/203)\u001b[K\rremote: Counting objects:  44% (90/203)\u001b[K\rremote: Counting objects:  45% (92/203)\u001b[K\rremote: Counting objects:  46% (94/203)\u001b[K\rremote: Counting objects:  47% (96/203)\u001b[K\rremote: Counting objects:  48% (98/203)\u001b[K\rremote: Counting objects:  49% (100/203)\u001b[K\rremote: Counting objects:  50% (102/203)\u001b[K\rremote: Counting objects:  51% (104/203)\u001b[K\rremote: Counting objects:  52% (106/203)\u001b[K\rremote: Counting objects:  53% (108/203)\u001b[K\rremote: Counting objects:  54% (110/203)\u001b[K\rremote: Counting objects:  55% (112/203)\u001b[K\rremote: Counting objects:  56% (114/203)\u001b[K\rremote: Counting objects:  57% (116/203)\u001b[K\rremote: Counting objects:  58% (118/203)\u001b[K\rremote: Counting objects:  59% (120/203)\u001b[K\rremote: Counting objects:  60% (122/203)\u001b[K\rremote: Counting objects:  61% (124/203)\u001b[K\rremote: Counting objects:  62% (126/203)\u001b[K\rremote: Counting objects:  63% (128/203)\u001b[K\rremote: Counting objects:  64% (130/203)\u001b[K\rremote: Counting objects:  65% (132/203)\u001b[K\rremote: Counting objects:  66% (134/203)\u001b[K\rremote: Counting objects:  67% (137/203)\u001b[K\rremote: Counting objects:  68% (139/203)\u001b[K\rremote: Counting objects:  69% (141/203)\u001b[K\rremote: Counting objects:  70% (143/203)\u001b[K\rremote: Counting objects:  71% (145/203)\u001b[K\rremote: Counting objects:  72% (147/203)\u001b[K\rremote: Counting objects:  73% (149/203)\u001b[K\rremote: Counting objects:  74% (151/203)\u001b[K\rremote: Counting objects:  75% (153/203)\u001b[K\rremote: Counting objects:  76% (155/203)\u001b[K\rremote: Counting objects:  77% (157/203)\u001b[K\rremote: Counting objects:  78% (159/203)\u001b[K\rremote: Counting objects:  79% (161/203)\u001b[K\rremote: Counting objects:  80% (163/203)\u001b[K\rremote: Counting objects:  81% (165/203)\u001b[K\rremote: Counting objects:  82% (167/203)\u001b[K\rremote: Counting objects:  83% (169/203)\u001b[K\rremote: Counting objects:  84% (171/203)\u001b[K\rremote: Counting objects:  85% (173/203)\u001b[K\rremote: Counting objects:  86% (175/203)\u001b[K\rremote: Counting objects:  87% (177/203)\u001b[K\rremote: Counting objects:  88% (179/203)\u001b[K\rremote: Counting objects:  89% (181/203)\u001b[K\rremote: Counting objects:  90% (183/203)\u001b[K\rremote: Counting objects:  91% (185/203)\u001b[K\rremote: Counting objects:  92% (187/203)\u001b[K\rremote: Counting objects:  93% (189/203)\u001b[K\rremote: Counting objects:  94% (191/203)\u001b[K\rremote: Counting objects:  95% (193/203)\u001b[K\rremote: Counting objects:  96% (195/203)\u001b[K\rremote: Counting objects:  97% (197/203)\u001b[K\rremote: Counting objects:  98% (199/203)\u001b[K\rremote: Counting objects:  99% (201/203)\u001b[K\rremote: Counting objects: 100% (203/203)\u001b[K\rremote: Counting objects: 100% (203/203), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 351 (delta 104), reused 186 (delta 94), pack-reused 148 (from 1)\u001b[K\n",
            "Receiving objects: 100% (351/351), 26.46 MiB | 27.73 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n",
            "/content/ehu_nlp_dimathina\n",
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n",
            "Switched to a new branch 'main'\n",
            "mv: cannot move 'Evaluation/' to '../Evaluation': Directory not empty\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "/content\n",
            "fatal: destination path 'triviaqa' already exists and is not an empty directory.\n",
            "rm: cannot remove 'sample_data': No such file or directory\n",
            "/content/triviaqa\n",
            "Requirement already satisfied: tensorflow>=0.11 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.17.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 2)) (2024.9.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=0.11->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=0.11->-r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=0.11->-r requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.1.2)\n",
            "/content/Evaluation\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 1)) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 1)) (1.16.0)\n",
            "/content/Dummy_Model\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CoPJQ6D3jpq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing the Evaluation Data\n",
        "\n",
        "**If you don't want to change the size evaluation dataset skip this step**\n",
        "\n",
        "This step is only required if you want to test the model with a larger dataset than the first 7900 questions of the train split of the triviaqa wikipedia dataset. In case you want to test a rag model that also uses the web dataset as vector database you can increase the evaluation dataset to the required first 9500 questions of the train split following these steps"
      ],
      "metadata": {
        "id": "H294GP72zhM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m Evaluation.utils.load_evaluation_data --split_size 9500"
      ],
      "metadata": {
        "id": "cV7pwZT11Pik",
        "outputId": "90861563-87f8-4f8e-9e57-fe36d5abcccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md: 100% 26.7k/26.7k [00:00<00:00, 54.3MB/s]\n",
            "Resolving data files: 100% 26/26 [00:00<00:00, 86.16it/s]\n",
            "train-00000-of-00007.parquet: 100% 240M/240M [00:01<00:00, 161MB/s]\n",
            "train-00001-of-00007.parquet: 100% 261M/261M [00:02<00:00, 106MB/s]\n",
            "train-00002-of-00007.parquet: 100% 319M/319M [00:01<00:00, 183MB/s]\n",
            "train-00003-of-00007.parquet: 100% 266M/266M [00:04<00:00, 55.5MB/s]\n",
            "train-00004-of-00007.parquet: 100% 240M/240M [00:01<00:00, 152MB/s]\n",
            "train-00005-of-00007.parquet: 100% 259M/259M [00:02<00:00, 88.6MB/s]\n",
            "train-00006-of-00007.parquet: 100% 253M/253M [00:05<00:00, 45.7MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 235M/235M [00:03<00:00, 75.4MB/s]\n",
            "test-00000-of-00001.parquet: 100% 221M/221M [00:02<00:00, 84.0MB/s]\n",
            "Generating train split: 100% 61888/61888 [00:40<00:00, 1523.56 examples/s]\n",
            "Generating validation split: 100% 7993/7993 [00:05<00:00, 1365.50 examples/s]\n",
            "Generating test split: 100% 7701/7701 [00:03<00:00, 1942.78 examples/s]\n",
            "Loading dataset: 100% 9500/9500 [00:09<00:00, 950.41it/s] \n",
            "Replacing field names: 100% 19/19 [00:21<00:00,  1.14s/it]\n",
            "Removing Wiki Context: 100% 9500/9500 [00:00<00:00, 437021.67it/s]\n",
            "Saving file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JPZ3SoyezfjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executing the Evaluation Chain\n",
        "Now you can run the Evaluation chain with the model of choice. In this case it is a dummy model to test the functionality of the evaluation chain. The dummy model always looksup the correct answer to every question.\n",
        "\n",
        "To start the evaluation chain type the following command\n",
        "\n",
        "`!python3 -m Evaluation.evaluation_chain --model_directory $DIRECTORY --model_module $MODULE --model_class $CLASS --model_params $PARAMS --split_size 7900`\n",
        "\n",
        "**If your model doesn't use any parameters please delete the `--model_params $PARAMS` section from the command**\n",
        "\n",
        "If you don't want to test the model against the entire evaluation set you can choose a smaller split size. Otherwise the maximum value of the split size is 7900"
      ],
      "metadata": {
        "id": "6uaV1IoKc2Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m Evaluation.evaluation_chain --model_directory $DIRECTORY --model_module $MODULE --model_class $CLASS --model_params $PARAMS --split_size 7900"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4Uk8IFdc1qA",
        "outputId": "39e6a9a5-f025-4494-c039-b6c451c5da16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rLoading Questions:   0% 0/7900 [00:00<?, ?it/s]\rLoading Questions: 100% 7900/7900 [00:00<00:00, 853752.84it/s]\n",
            "Loading model...\n",
            "This is param 1: hello\n",
            "This is param 2: world\n",
            "Model initiated\n",
            "Starting QA...\n",
            "\rRetrieving Answers:   0% 0/7900 [00:00<?, ?it/s]\rRetrieving Answers: 100% 7900/7900 [00:00<00:00, 620087.61it/s]\n",
            "QA complete\n",
            "Starting evaluation...\n",
            "Evaluation complete\n",
            "Saving results...\n",
            "Test results saved under Evaluation/results/dummy_model_split_size=7900_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of the test are saved in the file *dummy_model_split_size=7900_results.txt* in the Evaluation package\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9nCQuGJNgqxV"
      }
    }
  ]
}