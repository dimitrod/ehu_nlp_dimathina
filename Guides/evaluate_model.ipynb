{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4nNf53VQmS8Od9qHk+50Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitrod/ehu_nlp_dimathina/blob/chat_gpt/Guides/evaluate_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat GPT Test Environment\n",
        "Use this notebook to conduct single tests on the chapt gpt model"
      ],
      "metadata": {
        "id": "N6R7R18RhL1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xFRvUd8FjTnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Execute the following script to import the model and install the requirements"
      ],
      "metadata": {
        "id": "iO2nNW6kjU1m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH1mqdP9XZBY",
        "outputId": "7644fbe0-eae8-473a-b95c-9951a6c99454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ehu_nlp_dimathina'...\n",
            "remote: Enumerating objects: 683, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 683 (delta 125), reused 124 (delta 72), pack-reused 465 (from 1)\u001b[K\n",
            "Receiving objects: 100% (683/683), 28.00 MiB | 14.55 MiB/s, done.\n",
            "Resolving deltas: 100% (360/360), done.\n",
            "/content/ehu_nlp_dimathina\n",
            "/content\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r ChatGPT/requirements.txt (line 1)) (1.54.5)\n",
            "Collecting httpx==0.23.0 (from -r ChatGPT/requirements.txt (line 2))\n",
            "  Downloading httpx-0.23.0-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m832.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.23.0->-r ChatGPT/requirements.txt (line 2)) (2024.8.30)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.23.0->-r ChatGPT/requirements.txt (line 2)) (1.3.1)\n",
            "Collecting rfc3986<2,>=1.3 (from rfc3986[idna2008]<2,>=1.3->httpx==0.23.0->-r ChatGPT/requirements.txt (line 2))\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore<0.16.0,>=0.15.0 (from httpx==0.23.0->-r ChatGPT/requirements.txt (line 2))\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (2.10.3)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai->-r ChatGPT/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r ChatGPT/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r ChatGPT/requirements.txt (line 1)) (1.2.2)\n",
            "Collecting h11<0.13,>=0.11 (from httpcore<0.16.0,>=0.15.0->httpx==0.23.0->-r ChatGPT/requirements.txt (line 2))\n",
            "  Downloading h11-0.12.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r ChatGPT/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r ChatGPT/requirements.txt (line 1)) (2.27.1)\n",
            "Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rfc3986, h11, httpcore, httpx\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "Successfully installed h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 rfc3986-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!git clone --branch chat_gpt https://github.com/dimitrod/ehu_nlp_dimathina.git\n",
        "%cd ehu_nlp_dimathina\n",
        "%mv ChatGPT ..\n",
        "%cd ..\n",
        "%rm -r ehu_nlp_dimathina\n",
        "%rm -r sample_data\n",
        "!pip install -r ChatGPT/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an instance of the model"
      ],
      "metadata": {
        "id": "FAXrOR32ghSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ChatGPT.chat_gpt import chat_gpt\n",
        "\n",
        "params = []\n",
        "\n",
        "model = chat_gpt(params)"
      ],
      "metadata": {
        "id": "_9BLKq_PgU9g",
        "outputId": "2ebcedd7-11da-4057-9f26-19dbbb2a3f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Token: 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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "P_cg7cVsglsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests\n",
        "Start the tests that you want to conduct"
      ],
      "metadata": {
        "id": "zsoHYs5Fgnyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the capital of france?\"\n",
        "\n",
        "answer = model.invoke(question)\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "V_xw5na6gujx",
        "outputId": "768958ee-d849-423a-84a0-49253966ac12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris.\n"
          ]
        }
      ]
    }
  ]
}