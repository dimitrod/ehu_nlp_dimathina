{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXfynBPjSaxyzuDBi54mIj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitrod/ehu_nlp_dimathina/blob/main/Guides/evaluate_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "In this script you can evaluate any model that has been developed during the project using the evaluation data.\n",
        "\n",
        "By default the evaluation data has been set to be the entire validation split (7993 questions) of the triviaqa dataset.\n",
        "If you want to change the evaluation data to be a different split or a different default size for your tests you can do that using the *load_evaluation_data.py* script in the utils package. A guide for this is in the section [Changing the Evaluation Data](#scrollTo=H294GP72zhM9).\n",
        "\n"
      ],
      "metadata": {
        "id": "N6R7R18RhL1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xFRvUd8FjTnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "To import the model into the evaluation environment enter the parameters into the script below. Use the following table to find the right entries for each model:\n",
        "\n",
        "\n",
        "\n",
        "|Model|Context|Embedding|BRANCH|DIRECTORY|MODULE|CLASS|PARAMS|Note|\n",
        "|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
        "|Dummy Model|-|-|main|Dummy_Model|dummy_model|dummy_model|2 test params|-|\n",
        "|Tiny Llama|-|-|tiny_llama|TinyLlama|tiny_llama|tinyllama|-|**very slow**|\n",
        "|Tiny Llama|Whole documents|Dense|tiny_llama_rag|TinyLlamaRAG|tiny_llama_rag|tiny_llama_rag|||\n",
        "|Mistral Instruct|-|-|mistral-instruct-no-rag|MistralInstruct|mistral_instruct|mistral_instruct||**Huggingface Token and GPU required**|\n",
        "|Mistral Instruct|Whole documents|Dense|mistral-instruct|MistralInstruct|mistral_instruct|mistral_instruct|||\n",
        "|Bert Base|QA Pairs|Dense|rag_qa_embeddings|RAG_QA_Embeddings|rag_qa_embeddings|rag_qa_embeddings|k|-|\n",
        "|Bert Base|Whole documents|Dense|bert_base_rag|Bert_Base|bert_base|bert_base|||\n",
        "|Bert Base|Text Fragments|Sparse|bert_base_sparse_embeddings|RAG_Sparse_Embeddings|rag_sparse_embeddings|rag_sparse_embeddings|||\n",
        "|Bert Finetuned|Whole documents|Dense|bert_finetuned_rag|Bert_Finetuned|bert_finetuned|bert_finetuned|||\n",
        "|Mistral Instruct|Text Fragments|Sparse/Dense|rag_sparse_dense_embeddings|RAG_Sparse_Dense_Embeddings|rag_sparse_dense_embeddings|rag_sparse_dense_embeddings|k, c, o, t, mt||\n",
        "\n",
        "The meaning of each parameter can be found in this table\n",
        "\n",
        "|Parameter Name|Description|\n",
        "|----------|----------|\n",
        "|k|Number of contexts the retriever sends to the reader|\n",
        "|c|chunk size of each context|\n",
        "|o|overlap between the contexts|\n",
        "|t|temparature of the reader model|\n",
        "|mt|maximum amount of tokens generated by the reader model|\n",
        "\n",
        "If the model requires several parameters separate each parameter by a blank space."
      ],
      "metadata": {
        "id": "iO2nNW6kjU1m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qH1mqdP9XZBY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"BRANCH\"] = \"rag_sparse_dense_embeddings\"\n",
        "os.environ[\"DIRECTORY\"] = \"RAG_Sparse_Dense_Embeddings\"\n",
        "os.environ[\"MODULE\"] = \"rag_sparse_dense_embeddings\"\n",
        "os.environ[\"CLASS\"] = \"\trag_sparse_dense_embeddings\"\n",
        "os.environ[\"PARAMS\"] = \"10 300 0 0.5 30\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following script to setup the evaluation environment"
      ],
      "metadata": {
        "id": "LFeS1s_SYl3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = os.environ[\"DIRECTORY\"]\n",
        "\n",
        "!git clone --no-checkout https://github.com/dimitrod/ehu_nlp_dimathina.git\n",
        "%cd ehu_nlp_dimathina/\n",
        "!git sparse-checkout init --cone\n",
        "!git sparse-checkout set Evaluation/\n",
        "!git checkout main\n",
        "%mv Evaluation/ ..\n",
        "!git sparse-checkout set $DIRECTORY\n",
        "!git checkout $BRANCH\n",
        "%mv $DIRECTORY ..\n",
        "%cd ..\n",
        "!git clone https://github.com/mandarjoshi90/triviaqa.git\n",
        "%rm -r ehu_nlp_dimathina\n",
        "%rm -r sample_data\n",
        "%cd triviaqa/\n",
        "!pip install -r requirements.txt\n",
        "%cd ../Evaluation\n",
        "!pip install -r requirements.txt\n",
        "%cd ../{directory}\n",
        "!pip install -r requirements.txt\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBLrZP5RYNg4",
        "outputId": "ccf04f41-9450-48e7-96e8-567205b51ff1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ehu_nlp_dimathina'...\n",
            "remote: Enumerating objects: 648, done.\u001b[K\n",
            "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 648 (delta 110), reused 95 (delta 59), pack-reused 465 (from 1)\u001b[K\n",
            "Receiving objects: 100% (648/648), 27.99 MiB | 9.13 MiB/s, done.\n",
            "Resolving deltas: 100% (345/345), done.\n",
            "/content/ehu_nlp_dimathina\n",
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n",
            "Switched to a new branch 'main'\n",
            "Downloading RAG_Sparse_Dense_Embeddings/database/document_library.pkl (149 MB)\n",
            "Error downloading object: RAG_Sparse_Dense_Embeddings/database/document_library.pkl (6b3fb88): Smudge error: Error downloading RAG_Sparse_Dense_Embeddings/database/document_library.pkl (6b3fb883ce56e22c1ec1d009a2381aea7cf95e1ebe5b42f8d45bf0652638dd26): batch response: This repository is over its data quota. Account responsible for LFS bandwidth should purchase more data packs to restore access.\n",
            "\n",
            "Errors logged to /content/ehu_nlp_dimathina/.git/lfs/logs/20241215T105500.862878705.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: RAG_Sparse_Dense_Embeddings/database/document_library.pkl: smudge filter lfs failed\n",
            "/content\n",
            "Cloning into 'triviaqa'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Total 70 (delta 0), reused 0 (delta 0), pack-reused 70 (from 1)\u001b[K\n",
            "Receiving objects: 100% (70/70), 20.60 KiB | 2.94 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n",
            "/content/triviaqa\n",
            "Requirement already satisfied: tensorflow>=0.11 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.17.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 2)) (2024.9.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=0.11->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=0.11->-r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=0.11->-r requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.1.2)\n",
            "/content/Evaluation\n",
            "Collecting datasets (from -r requirements.txt (line 1))\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 1))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (4.66.6)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 1))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 1))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 1))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 1)) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "/content/RAG_Sparse_Dense_Embeddings\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.46.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.5.2)\n",
            "Collecting langchain_community (from -r requirements.txt (line 4))\n",
            "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting faiss-cpu (from -r requirements.txt (line 5))\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting faiss-gpu (from -r requirements.txt (line 6))\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community->-r requirements.txt (line 4)) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community->-r requirements.txt (line 4)) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.12 (from langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading langchain_core-0.3.25-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community->-r requirements.txt (line 4)) (0.2.2)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community->-r requirements.txt (line 4)) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 1)) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 1)) (4.12.2)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain<0.4.0,>=0.3.12->langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.12->langchain_community->-r requirements.txt (line 4)) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community->-r requirements.txt (line 4)) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community->-r requirements.txt (line 4)) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community->-r requirements.txt (line 4)) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community->-r requirements.txt (line 4)) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community->-r requirements.txt (line 4)) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community->-r requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain_community->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community->-r requirements.txt (line 4)) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 4))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community->-r requirements.txt (line 4)) (1.2.2)\n",
            "Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.12-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.25-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Downloading langchain_text_splitters-0.3.3-py3-none-any.whl (27 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: faiss-gpu, python-dotenv, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.24\n",
            "    Uninstalling langchain-core-0.3.24:\n",
            "      Successfully uninstalled langchain-core-0.3.24\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.2\n",
            "    Uninstalling langchain-text-splitters-0.3.2:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.2\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.11\n",
            "    Uninstalling langchain-0.3.11:\n",
            "      Successfully uninstalled langchain-0.3.11\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.9.0.post1 faiss-gpu-1.7.2 httpx-sse-0.4.0 langchain-0.3.12 langchain-core-0.3.25 langchain-text-splitters-0.3.3 langchain_community-0.3.12 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.7.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CoPJQ6D3jpq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing the Evaluation Data\n",
        "\n",
        "**If you don't want to change the split of the evaluation dataset skip this step**\n",
        "\n",
        "This step is only required if you want to evaluate with a different data set. You can change the evaluation dataset with the following command\n",
        "\n",
        "`!python3 -m Evaluation.utils.load_evaluation_data --split {split} --split_size {split_size}`\n",
        "\n",
        "Keep the maximum split sizes in mind"
      ],
      "metadata": {
        "id": "H294GP72zhM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m Evaluation.utils.load_evaluation_data --split \"train\" --split_size 7900"
      ],
      "metadata": {
        "id": "cV7pwZT11Pik",
        "outputId": "4d902f2c-9145-415d-8472-abcc9914bc07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md: 100% 26.7k/26.7k [00:00<00:00, 44.1MB/s]\n",
            "Resolving data files: 100% 26/26 [00:04<00:00,  5.25it/s]\n",
            "train-00000-of-00001.parquet: 100% 25.0M/25.0M [00:00<00:00, 68.8MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 3.31M/3.31M [00:00<00:00, 63.4MB/s]\n",
            "test-00000-of-00001.parquet: 100% 542k/542k [00:00<00:00, 219MB/s]\n",
            "Generating train split: 100% 61888/61888 [00:00<00:00, 120788.64 examples/s]\n",
            "Generating validation split: 100% 7993/7993 [00:00<00:00, 121794.20 examples/s]\n",
            "Generating test split: 100% 7701/7701 [00:00<00:00, 250788.73 examples/s]\n",
            "Loading dataset: 100% 7900/7900 [00:01<00:00, 3985.31it/s]\n",
            "Replacing field names: 100% 19/19 [00:00<00:00, 59.48it/s]\n",
            "Saving file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JPZ3SoyezfjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executing the Evaluation Chain\n",
        "Now you can run the Evaluation chain with the model of choice. To start the evaluation chain use the following command\n",
        "\n",
        "`!python3 -m Evaluation.evaluation_chain --model_directory $DIRECTORY --model_module $MODULE --model_class $CLASS --model_params $PARAMS`\n",
        "\n",
        "\n",
        "*   If the model doesn't require any params please remove `--model_params $PARAMS` from the command\n",
        "*   If you want to evaluate the model on a smaller split you can do that by adding --`split_size {split_size}`"
      ],
      "metadata": {
        "id": "6uaV1IoKc2Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m Evaluation.evaluation_chain --model_directory $DIRECTORY --model_module $MODULE --model_class $CLASS --model_params $PARAMS --split_size 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4Uk8IFdc1qA",
        "outputId": "5a4935e1-0ef6-48e9-c9bf-1231ff1ab361"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rLoading Questions:   0% 0/10 [00:00<?, ?it/s]\rLoading Questions: 100% 10/10 [00:00<00:00, 137518.16it/s]\n",
            "Loading model...\n",
            "2024-12-15 10:57:51.488762: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-15 10:57:51.512229: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-15 10:57:51.519848: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-15 10:57:51.536790: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-15 10:57:53.080219: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "2024-12-15 10:58:03.764631 : log in complete\n",
            "2024-12-15 10:58:03.764966 : loading vector base\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/Evaluation/evaluation_chain.py\", line 95, in <module>\n",
            "    model = load_model(model_path, model_name, model_params)\n",
            "  File \"/content/Evaluation/evaluation_chain.py\", line 60, in load_model\n",
            "    return model(model_params)\n",
            "  File \"/content/RAG_Sparse_Dense_Embeddings/rag_sparse_dense_embeddings.py\", line 33, in __init__\n",
            "    self.vector_base = joblib.load(self.database_path/\"document_library.pkl\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py\", line 650, in load\n",
            "    with open(filename, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/RAG_Sparse_Dense_Embeddings/database/document_library.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of the test are saved in the file *dummy_model_split_size=7900_results.txt* in the Evaluation package\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9nCQuGJNgqxV"
      }
    }
  ]
}