{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNWt5M5kHTdBLno1xafP+20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitrod/ehu_nlp_dimathina/blob/Evaluation/Evaluation_Chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l17utIMg3MX",
        "outputId": "79ad5d43-4a44-4ac3-f7f0-207fcecab137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'triviaqa'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Total 70 (delta 0), reused 0 (delta 0), pack-reused 70 (from 1)\u001b[K\n",
            "Receiving objects: 100% (70/70), 20.60 KiB | 781.00 KiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mandarjoshi90/triviaqa.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd triviaqa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAZi_7chimLA",
        "outputId": "7c998f9f-f2c6-47f8-a03e-4323ff442be2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/triviaqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69zKUTgIikD3",
        "outputId": "84ef64e2-a417-4236-fdaf-cd13c60c2fe5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow>=0.11 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.17.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=0.11->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 2)) (2024.9.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=0.11->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=0.11->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=0.11->-r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=0.11->-r requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=0.11->-r requirements.txt (line 1)) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import importlib\n",
        "import argparse"
      ],
      "metadata": {
        "id": "I7WlE5ehjWPB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triviaqa_root = \"/content/triviaqa\""
      ],
      "metadata": {
        "id": "a0RV2SptnCCX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = os.environ.copy()\n",
        "env[\"PYTHONPATH\"] = triviaqa_root"
      ],
      "metadata": {
        "id": "bpLDny15nG2g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZsr5DgTiuFb",
        "outputId": "6128e7a1-7627-42c4-b046-888579b0b220"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers huggingface_hub"
      ],
      "metadata": {
        "id": "1A3aDW8yB4yX",
        "outputId": "65ae859f-0271-4406-fcb1-69ab2ccca9bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_triviaqa(dataset_file, prediction_file):\n",
        "  script_path = \"/content/triviaqa/evaluation/triviaqa_evaluation.py\"\n",
        "  result = subprocess.run([\n",
        "    \"python\", script_path,\n",
        "    \"--dataset_file\", dataset_file,\n",
        "    \"--prediction_file\", prediction_file],\n",
        "    env=env,\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        "  )\n",
        "  print(result.stdout)"
      ],
      "metadata": {
        "id": "SS7fi6YaoUAc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answers(directory, questions, model):\n",
        "    answers = {}\n",
        "\n",
        "    for i in tqdm(range(len(questions)), desc=\"Retrieving Answers\"):\n",
        "        question = questions[i]\n",
        "        answers[question[0]] = model.invoke(question[1])\n",
        "    write_data(directory + \"/predictions.json\", answers)"
      ],
      "metadata": {
        "id": "UJkn-akWpoFy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_questions(path, split):\n",
        "    create_split(path, split)\n",
        "\n",
        "    with open(f\"{path}/evaluation_dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.loads(f.read())\n",
        "\n",
        "    questions = []\n",
        "\n",
        "    for i in tqdm(range(len(data[\"Data\"])),desc=\"Loading Questions\"):\n",
        "        question = data[\"Data\"][i]\n",
        "        questions.append([question[\"QuestionId\"], question[\"Question\"]])\n",
        "    return questions"
      ],
      "metadata": {
        "id": "fNCThm5Rpumf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_split(path, split):\n",
        "  with open(f\"{path}/original_dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.loads(f.read())\n",
        "\n",
        "  data[\"Data\"] = data[\"Data\"][:split]\n",
        "\n",
        "  write_data(f\"{path}/evaluation_dataset.json\", data)"
      ],
      "metadata": {
        "id": "B1YjpbupeNzx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(path, model_name):\n",
        "  module = importlib.import_module(path)\n",
        "  model = getattr(module, model_name)\n",
        "  print(\"Loading model...\")\n",
        "  return model()"
      ],
      "metadata": {
        "id": "ajbiOhUv6WN-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_data(path, data):\n",
        "  with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(json.dumps(data))"
      ],
      "metadata": {
        "id": "cY6kgFf_ik39"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_args():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='Evaluation Chain for TriviaQA {}')\n",
        "    parser.add_argument('--dataset_file', help='Dataset file')\n",
        "    parser.add_argument('--model_file', help='Model file')\n",
        "    args = parser.parse_args()\n",
        "    return args"
      ],
      "metadata": {
        "id": "3juSBi2YqEhS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #args = get_args()\n",
        "    directory = \"/content/evaluation_data\"\n",
        "    split = 10\n",
        "    model_path = \"model.tiny_llama\"\n",
        "    model_name = \"tinyllama\"\n",
        "\n",
        "\n",
        "    questions = load_questions(directory, split)\n",
        "    model = load_model(model_path, model_name)\n",
        "    print(\"Model initiated\")\n",
        "    print(\"Starting QA...\")\n",
        "    answers = get_answers(directory, questions, model)\n",
        "    print(\"QA complete\")\n",
        "    print(\"Test results:\")\n",
        "    evaluate_triviaqa(directory + \"/evaluation_dataset.json\", directory + \"/predictions.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQB9SZ_jqG2u",
        "outputId": "5fb2ac66-4d4a-4a07-98e5-db75d19ffb7f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Questions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 10743.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "Model initiated\n",
            "Starting QA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving Answers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [10:27<00:00, 62.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QA complete\n",
            "Test results:\n",
            "em=0: Dame Judi Dench was born in London, England. ['york yorkshire', 'eoferwic', 'park grove primary school', 'park grove school', 'weather in york', 'park grove 1895', 'eoforwic', 'county borough of york', 'york uk', 'un locode gbyrk', 'city of york', 'york england', 'york ua', 'york ham', 'york', 'yorkish', 'yoisk', 'york north yorkshire']\n",
            "em=0: Angola achieved independence from Portugal on January 10, 1975. ['portugul', 'portugallu', 'portugalska', 'pÃ²tigal', 'portugaul', 'portugalujo', 'portuguese republic', 'iso 3166 1 pt', 'republic of portugal', 'portugalsko', 'portugual', 'bá»“ Ä‘Ã o nha', 'portugall', 'portÃ»nga', 'bo dao nha', 'phortaingeil', 'portugale', 'portugal', 'portugÃ¡l', 'portugalÄ—jÄ—', 'portiwgal', 'phu to ga', 'portugalija', 'portugalio', 'portogallo', 'phÃ» tÃ´ gÃ¢', 'portegal', 'repÃºblica portuguesa', 'portugÄle', 'phortaingÃ©il', 'yn phortiugal', 'portogaÅ‚o', 'portuga', 'portugaleje', 'portekiz', 'o papagaio', 'portunga', 'potigal', 'portekÃ®z', 'pertual', 'portogalo', 'portugali', 'portyngal', 'republica portuguesa', 'portingale', 'portÃºgal', 'portgual', 'potiti']\n",
            "em=0: David Soul does not have a birthplace mentioned in his biography or personal details. He was born in London, United Kingdom. ['sayre language academy', 'chicago transportation committee', 'chicago illinois u s', 'sister cities of chicago', 'sister cities chicago', 'transport in chicago', 'chicago illinois', 'chicago illinois usa', 'chi town', 'hog butcher for world', 'religion in chicago', 'chicago', 'chicago wi', 'near north montessori', 'un locode uschi', 'city of broad shoulders', 'chicago theatre', 'chicago usa', 'uschi', 'chicago il', 'city of chicago', 'chicago finance committee', 'list of sister cities of chicago', 'chi beria', 'weather in chicago', 'chicago wisconsin', 'land of smelly onions', 'ariel community academy', 'chicago theater scene', 'chicago united states', 'paris of america', 'chicago illionis', 'chicago illinois united states', 'chcago', 'chi city', 'chicago illinois us', 'performing arts in chicago', 'chicago theatre scene', 'chichago', 'chicago ill', 'city of chicago illinois']\n",
            "em=0: The Super Bowl XX was played on February 15, 1986, between the Chicago Bulls and the Washington Bullets. The Chicago Bulls won the game, 46-10, and became the first team to win back-to-back Super Bowls. ['chicago bears', 'chicago staleys', 'chicago gators', 'decatur staleys', 'save da planet', 'chicago bears football']\n",
            "em=0: The first European country to abolish capital punishment was Denmark, which did so in 1849. The Danish parliament passed a law to abolish capital punishment, which was signed by the king and became law in 1849. ['norwegen', 'kongeriket norge', 'norway', 'republic of norway', 'noorwegen', 'norvege', 'mainland norway', 'kingdom of norway', 'sport in norway', 'noreg', 'noruega', 'norwegia', 'noregur', 'royal kingdom of norway', 'name of norway', 'kongeriket noreg', 'norwegian kingdom', 'etymology of norway', 'norvÃ¨ge', 'iso 3166 1 no', 'norwegian state']\n",
            "em=0: The answer is: In the United Kingdom. In 1988, the UK government began implementing the Intelligent Services Distribution Network (ISDN), also known as ISDN, which allowed for the transmission of high-speed digital data between the UK's central offices and local exchange carrier (LE ['nihon koku', 'nihon', 'japoa', 'japang', 'japan', 'æ—¥æœ¬åœ‹', 'etymology of japan', 'iso 3166 1 jp', 'jpan', 'japan country', 'riben', 'rÃ¬bÄ›n', 'ğŸ—¾', 'japanese financial sector', 'japian', 'nippon koku', 'state of japan', 'nippon', 'modernâ€“era japan', 'republic of japan', 'æ—¥æœ¬å›½', 'jpn', 'japao', 'ja pan', 'æ—¥æœ¬']\n",
            "em=0: Bruce Willis' real first name is Bruce. He has never used an alias or stage name for himself. ['walter disambiguation', 'walter', 'walter tv series']\n",
            "em=0: The novel Lord Of The Flies by William Golding is not a chatbot. It is a novel written by an author, William Golding, who wrote it in 1954. ['golding', 'golding surname', 'golding disambiguation']\n",
            "em=0: Joan Molinsky is better known as:\n",
            "1. Joan Molinsky: A writer and educator, Joan Molinsky is best known for her books and articles on communication and leadership.\n",
            "2. Joan M. Molinsky: A writer and educator, Joan Molinsky is also known ['joan rivers', 'queen of comedy', 'diary of mad diva', 'joan rivers tv show', 'joan rivers show', 'joan alexandra molinsky', 'heidi abromowitz', 'joan river']\n",
            "em=0: Patricia Neary is best known as a contemporary dancer, choreographer, and teacher. She is also known for her work as a choreographer and director of the Irish National Dance Company, which she co-founded in 1972. In addition, she has performed and ['balletti', 'un locode inblt', '1916 ballet premieres', 'ballet', 'ballets', 'balletomane', 'ballet schools', '1938 ballet premieres', '1939 ballet premieres', '1940 ballet premieres', 'balletto', 'ballet competitions', 'balet', 'classical dance', '1914 ballet premieres', 'balet india', '1915 ballet premieres', 'ballett', 'ballet dancing', 'balletomanes', 'ballet dance', 'ballet teachers', '2011 ballet premieres', 'ballet characters', 'ballet lessons']\n",
            "{'exact_match': 0.0, 'f1': 8.802167526607674, 'common': 10, 'denominator': 10, 'pred_len': 10, 'gold_len': 10}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}